{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TfsG4A6spmpU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd157ec6-30d2-48cd-9576-c1b154c9c7f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-pretrained-bert pytorch-nlp\n",
        "!pip install -q transformers\n",
        "!pip install Keras-Preprocessing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2vpNUulu_P-",
        "outputId": "0f4a7e77-710e-4088-f6b4-bce9b9ced9e9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pytorch-pretrained-bert in /usr/local/lib/python3.9/dist-packages (0.6.2)\n",
            "Requirement already satisfied: pytorch-nlp in /usr/local/lib/python3.9/dist-packages (0.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from pytorch-pretrained-bert) (1.22.4)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.9/dist-packages (from pytorch-pretrained-bert) (1.26.117)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from pytorch-pretrained-bert) (4.65.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.9/dist-packages (from pytorch-pretrained-bert) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from pytorch-pretrained-bert) (2.27.1)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from pytorch-pretrained-bert) (2.0.0+cu118)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.1.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.11.0)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (2.0.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (1.11.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=0.4.1->pytorch-pretrained-bert) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=0.4.1->pytorch-pretrained-bert) (16.0.1)\n",
            "Requirement already satisfied: botocore<1.30.0,>=1.29.117 in /usr/local/lib/python3.9/dist-packages (from boto3->pytorch-pretrained-bert) (1.29.117)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.9/dist-packages (from boto3->pytorch-pretrained-bert) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from boto3->pytorch-pretrained-bert) (0.6.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->pytorch-pretrained-bert) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->pytorch-pretrained-bert) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->pytorch-pretrained-bert) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->pytorch-pretrained-bert) (1.26.15)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.9/dist-packages (from botocore<1.30.0,>=1.29.117->boto3->pytorch-pretrained-bert) (2.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=0.4.1->pytorch-pretrained-bert) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=0.4.1->pytorch-pretrained-bert) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.30.0,>=1.29.117->boto3->pytorch-pretrained-bert) (1.16.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: Keras-Preprocessing in /usr/local/lib/python3.9/dist-packages (1.1.2)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.9/dist-packages (from Keras-Preprocessing) (1.22.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.9/dist-packages (from Keras-Preprocessing) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from IPython.display import Image\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer\n",
        "from transformers import AdamW, BertForTokenClassification, get_linear_schedule_with_warmup\n",
        "from tqdm import tqdm, trange\n",
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "import re"
      ],
      "metadata": {
        "id": "8F6Y_YcxvEqF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSNHGOFtvPmN",
        "outputId": "63e6ab1e-4134-48a0-f511-b499fb35051c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/data_final.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "R8KRQhH0vSUW",
        "outputId": "f0667e83-9ac7-45b8-e57f-44c070bbd9ca"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0.1  index  Unnamed: 0  \\\n",
              "0             0      0           0   \n",
              "1             1      1           1   \n",
              "2             2      2           2   \n",
              "3             3      3           3   \n",
              "4             4      4           4   \n",
              "\n",
              "                                                text  \\\n",
              "0   \"Day 1: Arrive in Goa and check into your hot...   \n",
              "1  \"Day 1: Arrive in Pune and check into your hot...   \n",
              "2  Day 1: Arrive in Mumbai and check into your ho...   \n",
              "3  Day 1: Arrive in Panchgani and check into your...   \n",
              "4  Day 1: Arrive in Mahabaleshwar and check into ...   \n",
              "\n",
              "                                                name  \n",
              "0  ['Anjuna Beach', 'Vagator Beach', 'Dudhsagar W...  \n",
              "1  ['Pune', 'Aga Khan Palace', 'Pataleshwar Cave ...  \n",
              "2  ['Mumbai', 'Gateway of India', 'Elephanta Cave...  \n",
              "3  ['Panchgani', 'Sydney Point', 'Table Land', 'M...  \n",
              "4  ['Mahabaleshwar', \"Arthur's Seat\", 'Pratapgad ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2e6ec7c6-72a3-4902-8a61-ea8f2be5d76a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>index</th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>text</th>\n",
              "      <th>name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>\"Day 1: Arrive in Goa and check into your hot...</td>\n",
              "      <td>['Anjuna Beach', 'Vagator Beach', 'Dudhsagar W...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>\"Day 1: Arrive in Pune and check into your hot...</td>\n",
              "      <td>['Pune', 'Aga Khan Palace', 'Pataleshwar Cave ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>Day 1: Arrive in Mumbai and check into your ho...</td>\n",
              "      <td>['Mumbai', 'Gateway of India', 'Elephanta Cave...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>Day 1: Arrive in Panchgani and check into your...</td>\n",
              "      <td>['Panchgani', 'Sydney Point', 'Table Land', 'M...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>Day 1: Arrive in Mahabaleshwar and check into ...</td>\n",
              "      <td>['Mahabaleshwar', \"Arthur's Seat\", 'Pratapgad ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2e6ec7c6-72a3-4902-8a61-ea8f2be5d76a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2e6ec7c6-72a3-4902-8a61-ea8f2be5d76a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2e6ec7c6-72a3-4902-8a61-ea8f2be5d76a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(['Unnamed: 0','Unnamed: 0.1','index'], axis=1)"
      ],
      "metadata": {
        "id": "mSA3M3fnEFSW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['name'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "BVlHcP419kpl",
        "outputId": "1f9ce445-89de-43bc-a431-60e05c630ab9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"['Anjuna Beach', 'Vagator Beach', 'Dudhsagar Waterfalls', 'Old Goa', 'Mandovi River', 'Divar', 'St. Mathias Church', 'Our Lady of Compassion Chapel', 'Piedade', 'Fort Aguada', 'Candolim', 'Calangute', 'Salim Ali Bird Sanctuary', 'Panaji', 'Colva', 'Palolem', 'Cotigao Wildlife Sanctuary']\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_list = []\n",
        "all_places = df['name'][:]\n",
        "for data in all_places:\n",
        "  l = data[1:-1].split(',')\n",
        "  final_list = []\n",
        "  for place in l:\n",
        "    if place[0] == ' ':\n",
        "      final_list.append(place[2:-1])\n",
        "    else :\n",
        "      final_list.append(place[1:-1])\n",
        "  new_list.append(final_list)"
      ],
      "metadata": {
        "id": "_kzrgiTUAaXn"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['name'] = new_list"
      ],
      "metadata": {
        "id": "MPXXxsi3FKLY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "eUEBB_caBEyd",
        "outputId": "cc8012ab-3ea4-431b-fa0d-1187437713d0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text  \\\n",
              "0      \"Day 1: Arrive in Goa and check into your hot...   \n",
              "1     \"Day 1: Arrive in Pune and check into your hot...   \n",
              "2     Day 1: Arrive in Mumbai and check into your ho...   \n",
              "3     Day 1: Arrive in Panchgani and check into your...   \n",
              "4     Day 1: Arrive in Mahabaleshwar and check into ...   \n",
              "...                                                 ...   \n",
              "1403  I recently took a trip to Bordeaux and was blo...   \n",
              "1404  I recently took a trip to Paris and was amazed...   \n",
              "1405  On my last visit to Lyon, I was blown away by ...   \n",
              "1406  Paris is known for its romantic atmosphere and...   \n",
              "1407  When it comes to French cuisine, there are few...   \n",
              "\n",
              "                                                   name  \n",
              "0     [Anjuna Beach, Vagator Beach, Dudhsagar Waterf...  \n",
              "1     [Pune, Aga Khan Palace, Pataleshwar Cave Templ...  \n",
              "2     [Mumbai, Gateway of India, Elephanta Caves, Ma...  \n",
              "3     [Panchgani, Sydney Point, Table Land, Mahabale...  \n",
              "4     [Mahabaleshwar, Arthur's Seat, Pratapgad Fort,...  \n",
              "...                                                 ...  \n",
              "1403  [Le Chapon Fin, Garopapilles, La Tupina, Maiso...  \n",
              "1404         [L'Ambroisie, Septime, Chez Paul, Ladurée]  \n",
              "1405         [Chez Hugon, Paul Bocuse, Fromagerie Mons]  \n",
              "1406       [Le Jules Verne, Chez L'Ami Jean, Guy Savoy]  \n",
              "1407  [Paul Bocuse, L'Auberge du Pont de Collonges, ...  \n",
              "\n",
              "[1408 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-31bf9a51-4ccd-4b11-95ed-3ad54c550a80\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"Day 1: Arrive in Goa and check into your hot...</td>\n",
              "      <td>[Anjuna Beach, Vagator Beach, Dudhsagar Waterf...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"Day 1: Arrive in Pune and check into your hot...</td>\n",
              "      <td>[Pune, Aga Khan Palace, Pataleshwar Cave Templ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Day 1: Arrive in Mumbai and check into your ho...</td>\n",
              "      <td>[Mumbai, Gateway of India, Elephanta Caves, Ma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Day 1: Arrive in Panchgani and check into your...</td>\n",
              "      <td>[Panchgani, Sydney Point, Table Land, Mahabale...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Day 1: Arrive in Mahabaleshwar and check into ...</td>\n",
              "      <td>[Mahabaleshwar, Arthur's Seat, Pratapgad Fort,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1403</th>\n",
              "      <td>I recently took a trip to Bordeaux and was blo...</td>\n",
              "      <td>[Le Chapon Fin, Garopapilles, La Tupina, Maiso...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1404</th>\n",
              "      <td>I recently took a trip to Paris and was amazed...</td>\n",
              "      <td>[L'Ambroisie, Septime, Chez Paul, Ladurée]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1405</th>\n",
              "      <td>On my last visit to Lyon, I was blown away by ...</td>\n",
              "      <td>[Chez Hugon, Paul Bocuse, Fromagerie Mons]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1406</th>\n",
              "      <td>Paris is known for its romantic atmosphere and...</td>\n",
              "      <td>[Le Jules Verne, Chez L'Ami Jean, Guy Savoy]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1407</th>\n",
              "      <td>When it comes to French cuisine, there are few...</td>\n",
              "      <td>[Paul Bocuse, L'Auberge du Pont de Collonges, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1408 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-31bf9a51-4ccd-4b11-95ed-3ad54c550a80')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-31bf9a51-4ccd-4b11-95ed-3ad54c550a80 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-31bf9a51-4ccd-4b11-95ed-3ad54c550a80');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating sentence, label lists and adding Bert tokens\n",
        "sentences = df.text.values\n",
        "\n",
        "# Adding CLS and SEP tokens at the beginning and end of each sentence for BERT\n",
        "sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in sentences]"
      ],
      "metadata": {
        "id": "rjLkCpnQwdiK"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Activating the BERT Tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "MAX_LEN = 512"
      ],
      "metadata": {
        "id": "PaeoIwh30KrS"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = [tokenizer.encode(x,add_special_tokens=True) for x in sentences]\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")"
      ],
      "metadata": {
        "id": "PDsBAZ_58V0H"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_label(text, labels):\n",
        "  # Tokenize the input text\n",
        "  tokenized_text = tokenizer.encode(text, add_special_tokens=True)\n",
        "  # Initialize the label list with \"O\" (outside) label for each token\n",
        "  token_labels = [\"O\"] * len(tokenized_text)\n",
        "\n",
        "  # Find the indices of the restaurant name tokens in the input text\n",
        "  for label in labels:\n",
        "    # Tokenize the restaurant name and get its token IDs\n",
        "    tokenized_restaurant_name = tokenizer.encode(label, add_special_tokens=True)\n",
        "    restaurant_name_ids = tokenized_restaurant_name[1:-1]  # exclude the [CLS] and [SEP] tokens\n",
        "\n",
        "    for i in range(len(tokenized_text) - len(restaurant_name_ids) + 1):\n",
        "        if tokenized_text[i:i+len(restaurant_name_ids)] == restaurant_name_ids:\n",
        "            # Mark the restaurant name tokens with the \"B-RESTAURANT\" (beginning) label\n",
        "            token_labels[i] = \"B-RESTAURANT\"\n",
        "            for j in range(i+1, i+len(restaurant_name_ids)):\n",
        "                # Mark the remaining tokens of the restaurant name with the \"I-RESTAURANT\" (inside) label\n",
        "                token_labels[j] = \"I-RESTAURANT\"\n",
        "\n",
        "  # Print the tokenized input text and corresponding labels\n",
        "  return token_labels"
      ],
      "metadata": {
        "id": "3JBl6_PbDqjx"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_labels = []\n",
        "for p in range (0,len(df)):\n",
        "  text = df['text'][p]\n",
        "  label = df['name'][p]\n",
        "  label = tokenize_label(text, label)\n",
        "  input_labels.append(label)"
      ],
      "metadata": {
        "id": "-OOX7Hv5_Xn_"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the labels to label IDs\n",
        "label_ids = []\n",
        "for label_list in input_labels:\n",
        "    label_ids.append([2 if label == \"B-RESTAURANT\" else 3 if label == \"I-RESTAURANT\" else 1 for label in label_list])\n",
        "label_ids = pad_sequences(label_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")"
      ],
      "metadata": {
        "id": "RDtXsG4hExH4"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask)\n",
        "train_ids = input_ids\n",
        "train_label = label_ids\n",
        "train_attention_masks = attention_masks"
      ],
      "metadata": {
        "id": "ddwwiV04BLDe"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_attention_masks[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHs_VqaOJnnT",
        "outputId": "19b66e18-6e57-4426-cc57-c2652ec0bf33"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "512"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting data into train and validation sets\n",
        "# Use train_test_split to split our data into train and validation sets for training\n",
        "\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(train_ids, train_label,random_state = 2018, test_size = 0.1 )\n",
        "train_masks, validation_masks, _, _ = train_test_split(train_attention_masks, train_ids,\n",
        "                                             random_state=2018, test_size=0.1)\n",
        "     "
      ],
      "metadata": {
        "id": "_X9N5rLjE_yW"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYMWfHSoFL1q",
        "outputId": "934720f9-0e0c-45c8-ac74-257c8ef8e108"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 2, 3, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [1, 2, 3, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting all the data into torch tensors\n",
        "# Torch tensors are the required datatype for our model\n",
        "\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)\n",
        "print(type(train_inputs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xXt4V6jFCwV",
        "outputId": "49881c02-41c3-4a42-b412-538091596e4b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting a Batch Size and Creating and Iterator\n",
        "# Select a batch size for training. For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32\n",
        "batch_size = 4\n",
        "\n",
        "# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n",
        "# with an iterator the entire dataset does not need to be loaded into memory\n",
        "print(len(train_inputs))\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z13wJKETFGZ5",
        "outputId": "7f3e1c50-cf08-4fd2-f8e7-44bc309d8806"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1267\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Bert Model Configuration\n",
        "# Initializing a BERT bert-base-uncased style configuration\n",
        "# Transformer Installation\n",
        "try:\n",
        "  import transformers\n",
        "except:\n",
        "  print(\"Installing transformers\")\n",
        "  !pip -qq install transformers\n",
        "  \n",
        "from transformers import BertModel, BertConfig\n",
        "configuration = BertConfig()\n",
        "\n",
        "# Initializing a model from the bert-base-uncased style configuration\n",
        "# This process will load only configuration and not the weights associated with the model\n",
        "model = BertModel(configuration)\n",
        "\n",
        "# Accessing the model configuration\n",
        "configuration = model.config\n",
        "print(configuration)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxmmHkMxGulJ",
        "outputId": "21e04204-7247-43b4-aa1f-f74de61514c7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BertConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.28.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the Hugging Face Bert Uncased Base Model \n",
        "model = BertForTokenClassification.from_pretrained(\"bert-base-cased\",num_labels=len(df),\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False)\n",
        "model = nn.DataParallel(model)\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJVhpBAqG6G7",
        "outputId": "01871f6e-da90-4c43-edfc-5056599c2600"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataParallel(\n",
              "  (module): BertForTokenClassification(\n",
              "    (bert): BertModel(\n",
              "      (embeddings): BertEmbeddings(\n",
              "        (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
              "        (position_embeddings): Embedding(512, 768)\n",
              "        (token_type_embeddings): Embedding(2, 768)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (encoder): BertEncoder(\n",
              "        (layer): ModuleList(\n",
              "          (0-11): 12 x BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (classifier): Linear(in_features=768, out_features=1408, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimizer Grouped Parameters\n",
        "# reference:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L102\n",
        "\n",
        "\n",
        "# Don't apply weight decay to any parameters whose names include these tokens.\n",
        "# (Here, the BERT doesn't have `gamma` or `beta` parameters, only `bias` terms)\n",
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "# Separate the `weight` parameters from the `bias` parameters. \n",
        "# - For the `weight` parameters, this specifies a 'weight_decay_rate' of 0.01. \n",
        "# - For the `bias` parameters, the 'weight_decay_rate' is 0.0. \n",
        "optimizer_grouped_parameters = [\n",
        "    # Filter for all parameters which *don't* include 'bias', 'gamma', 'beta'.\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.1},\n",
        "    \n",
        "    # Filter for parameters which *do* include those.\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.0}\n",
        "]\n",
        "# Note - `optimizer_grouped_parameters` only includes the parameter values, not \n",
        "# the names."
      ],
      "metadata": {
        "id": "fCls99Y1G_Q_"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The Hyperparameters for the Training Loop \n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 3\n",
        "\n",
        "optimizer = AdamW(optimizer_grouped_parameters,\n",
        "                  lr = 3e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                  )\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "# `train_dataloader` contains batched data so `len(train_dataloader)` gives \n",
        "# us the number of batches.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0.1, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CczY9sVHHKPX",
        "outputId": "d7b29e69-b695-40ab-811b-a98394b622e2"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating the Accuracy Measurement Function\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = preds.flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "metadata": {
        "id": "3MSL-euAHMjh"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The Training Loop\n",
        "t = [] \n",
        "\n",
        "# Store our loss and accuracy for plotting\n",
        "train_loss_set = []\n",
        "\n",
        "# trange is a tqdm wrapper around the normal python range\n",
        "for _ in trange(epochs, desc=\"Epoch\"):\n",
        "  \n",
        "  \n",
        "  # Training\n",
        "  \n",
        "  # Set our model to training mode (as opposed to evaluation mode)\n",
        "  model.train()\n",
        "  \n",
        "  # Tracking variables\n",
        "  tr_loss = 0\n",
        "  nb_tr_examples, nb_tr_steps = 0, 0\n",
        "  \n",
        "  # Train the data for one epoch\n",
        "  for step, batch in enumerate(train_dataloader):\n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    # Clear out the gradients (by default they accumulate)\n",
        "    optimizer.zero_grad()\n",
        "    # Forward pass\n",
        "    outputs = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n",
        "    loss = outputs['loss']\n",
        "    train_loss_set.append(loss.item())    \n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "    # Update parameters and take a step using the computed gradient\n",
        "    optimizer.step()\n",
        "\n",
        "    # Update the learning rate.\n",
        "    scheduler.step()\n",
        "    \n",
        "    \n",
        "    # Update tracking variables\n",
        "    tr_loss += loss.item()\n",
        "    nb_tr_examples += b_input_ids.size(0)\n",
        "    nb_tr_steps += 1\n",
        "\n",
        "  print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
        "  # Validation\n",
        "\n",
        "  # Put model in evaluation mode to evaluate loss on the validation set\n",
        "  model.eval()\n",
        "\n",
        "  # Tracking variables \n",
        "  eval_loss, eval_accuracy = 0, 0\n",
        "  nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "  # Evaluate data for one epoch\n",
        "  for batch in validation_dataloader:\n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
        "    with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      logits = model(b_input_ids, attention_mask=b_input_mask)\n",
        "    \n",
        "    # Move logits and labels to CPU\n",
        "    logits = np.argmax(logits[0].to('cpu').numpy(), axis=2)\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    #print(logits == label_ids)\n",
        "\n",
        "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "    \n",
        "    eval_accuracy += tmp_eval_accuracy\n",
        "    nb_eval_steps += 1\n",
        "\n",
        "  print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dywJnnpBHP65",
        "outputId": "fd949e82-0a6b-4497-b677-7d60102d9b83"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:   0%|          | 0/3 [00:00<?, ?it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model,r'/content/drive/MyDrive/BERT_text.pt')"
      ],
      "metadata": {
        "id": "1QL5bA-Bz0uY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load(r'/content/drive/MyDrive/BERT_text.pt')"
      ],
      "metadata": {
        "id": "PQWTb0uFz717"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent = 'The Chug Garage is a funky pub where you can chug beer and groove to some live music'"
      ],
      "metadata": {
        "id": "t03_McQWH7Gh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_string(list):\n",
        "  l = []\n",
        "  for ele in list:\n",
        "    if ele == ' ' or ele == '':\n",
        "      pass\n",
        "    else:\n",
        "      l.append(ele)\n",
        "  return l\n",
        "\n",
        "def add_suffix(p):\n",
        "  match = re.search(p,sent)\n",
        "  # Define a list of categories to check against\n",
        "  categories = ['Restaurant', 'Cafe', 'House', 'Bar', 'Pub', 'Kitchen','Club','Bakery','Shop','Room','Shack']\n",
        "  if match:\n",
        "    for category in categories:\n",
        "        if match.end() < len(sent) and sent[match.end():].lower().startswith(category.lower()):\n",
        "            l = match.group() + '' + category\n",
        "            return l\n",
        "            break\n",
        "    return match.group()\n",
        "      \n",
        "  else:\n",
        "    return p"
      ],
      "metadata": {
        "id": "Yzalk6d1rGGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_location(sent):\n",
        "  \"\"\" extrecting location \"\"\"\n",
        "  true_label = []\n",
        "  tokenized_sentence = tokenizer.encode(sent)\n",
        "  input_ids = torch.tensor([tokenized_sentence])\n",
        "  with torch.no_grad():\n",
        "    output = model(input_ids)\n",
        "  label_indices = np.argmax(output[0].to('cpu').numpy(), axis=2)\n",
        "  tokens = tokenizer.convert_ids_to_tokens(input_ids.to('cpu').numpy()[0])\n",
        "  new_tokens, new_labels = [], []\n",
        "  for token, label_idx in zip(tokens, label_indices[0]):\n",
        "      if token.startswith(\"##\"):\n",
        "          new_tokens[-1] = new_tokens[-1] + token[2:]\n",
        "      else:\n",
        "          new_labels.append(label_idx)\n",
        "          new_tokens.append(token)\n",
        "  for token, label in zip(new_tokens, new_labels):\n",
        "    if (label==3):\n",
        "      true_label.append(token)\n",
        "    else:\n",
        "      true_label.append('#')\n",
        "  \n",
        "  # Join the words into a single string\n",
        "  label = \" \".join(true_label)\n",
        "  label = label.replace(\" ' s\",\"'s\")\n",
        "  l = label.split('#')\n",
        "  p = clean_string(l)\n",
        "\n",
        "  \"\"\"  Adding suffixes \"\"\"\n",
        "  final_list = []\n",
        "  for ele in p:\n",
        "    final_list.append(add_suffix(ele))\n",
        "  \n",
        "  return final_list\n"
      ],
      "metadata": {
        "id": "EaSEwnPMQf8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def multiline_data(text):\n",
        "  names = []\n",
        "  l = text.split(\".\")\n",
        "  for sent in l:\n",
        "    names.append(extract_location(sent))\n",
        "  return list(filter(None,names))\n"
      ],
      "metadata": {
        "id": "oRqEIzJv8BJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extract_location('We will go to either The Chocolate Room or Virgin Courtyard')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKOTxXTggz9m",
        "outputId": "12815d52-e1bd-49f7-c98d-45797a3d7194"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' either The Chocolate Room', ' Virgin Courtyard ']"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "extract_location(\"One of the most popular spots is Karim's near Jama Masjid, which has been serving delicious Mughlai cuisine for over a century. Another great option is The Big Chill Cafe in Khan Market, which offers a variety of international cuisine like Italian and American.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YODr6DNxSJ9",
        "outputId": "cbec2a5a-57e0-43e2-8ffe-a946f5190d6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\" Karim ' \", ' Jama Masjid ', ' The Big Chill ']"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "G = multiline_data(goa)"
      ],
      "metadata": {
        "id": "rwEgoLScSoBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "C = multiline_data(chandigarh)"
      ],
      "metadata": {
        "id": "K1FalG3UYra8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "S = multiline_data(surat)"
      ],
      "metadata": {
        "id": "0WZxncUCXjCX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "D = multiline_data(delhi)"
      ],
      "metadata": {
        "id": "KO8CjJkrXo74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "M = multiline_data(mumbai)"
      ],
      "metadata": {
        "id": "lje2JFhQX8fK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "K = multiline_data(kolkata)"
      ],
      "metadata": {
        "id": "SdGy1kuVYZQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "goa = \"\"\" Goa is a beautiful coastal state in India, known for its stunning beaches, vibrant nightlife, and delicious food. If you're looking for some nice restaurants and pubs in Goa, there are several options to choose from.\n",
        "\n",
        "For a fine dining experience, you can visit Thirsty Bear Kitchen and Bar in Panaji, which offers a great selection of cocktails, global cuisine, and live music performances. Another popular restaurant is Gunpowder in Assagao, which serves delicious North Indian and Goan cuisine, along with a variety of cocktails and drinks.\n",
        "\n",
        "If you're looking for a casual dining experience, you can try out Fisherman's Wharf in Panaji, which offers a beautiful view of the river, along with some amazing seafood and traditional Goan dishes. Another option is Mum's Kitchen in Panaji, which serves authentic Goan cuisine in a cozy and comfortable ambiance.\n",
        "\n",
        "For those looking for a night out, there are several nice pubs in Goa, such as Cafe Mambos in Baga, which is known for its energetic nightlife and dance performances. Another popular option is Tito's Club in Calangute, which has been a popular destination for partygoers for several decades, with a great selection of drinks, music, and entertainment.\n",
        "\n",
        "Overall, Goa has a variety of restaurants and pubs to choose from, catering to different tastes and budgets. Whether you're looking for a fine dining experience, a casual dinner with family or friends, or a night out with music and drinks, Goa has something for everyone.\"\"\""
      ],
      "metadata": {
        "id": "s6xmPt_VDmO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chandigarh = \"\"\"Chandigarh is known for its lively food scene, and there is no shortage of great restaurants and pubs in the city. One of the must-visit restaurants is the Virgin Courtyard, which serves Italian cuisine in a beautiful courtyard setting. Another great option is the Pal Dhaba, which is famous for its Punjabi dishes like butter chicken and dal makhani. If you're in the mood for some fusion food, head to The Hedgehog Cafe, which offers a mix of Italian and Indian cuisine.\n",
        "For those looking for a night out, there are plenty of pubs and bars in Chandigarh that offer a great atmosphere and delicious drinks. One of the most popular spots is The Backroom, which has a cozy atmosphere and serves an extensive range of cocktails. Another great option is the Ministry Of Bar Exchange, which is known for its lively vibe and great music. Finally, if you're looking for a more laid-back setting, head to The Great Bear, which offers a relaxed atmosphere and a wide selection of beers and wines.\"\"\""
      ],
      "metadata": {
        "id": "Z1enTzlFQVIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "delhi = \"\"\"\n",
        "Delhi is a food lover's paradise with a wide range of restaurants and pubs to choose from. If you're looking for a fine-dining experience, head to Indian Accent in The Lodhi Hotel, which is known for its innovative Indian cuisine. Another popular fine-dining option is Dum Pukht in ITC Maurya, which is famous for its Awadhi cuisine.\n",
        "For those who prefer a more casual dining experience, there are plenty of great options available in Delhi. One of the most popular spots is Karim's near Jama Masjid, which has been serving delicious Mughlai cuisine for over a century. Another great option is The Big Chill Cafe in Khan Market, which offers a variety of international cuisine like Italian and American.\n",
        "If you're in the mood for some nightlife, Delhi has a vibrant pub scene. One of the most popular spots is Farzi Cafe in Connaught Place, which offers great food and drinks, as well as a lively atmosphere. Another great option is PCO in Vasant Vihar, which is a speakeasy-style bar known for its creative cocktails.\n",
        "\n",
        "Finally, for those who enjoy rooftop bars, head to Aer in the Four Seasons Hotel, which offers stunning views of the city skyline and delicious drinks. Another great option is Smoke House Deli in Hauz Khas Village, which has a beautiful terrace and a great selection of cocktails and small plates.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "YkE1Ov4gQ08Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "surat = '''Surat is a city known for its delicious street food, but there are also plenty of great restaurants and pubs to explore. One of the most popular spots is The Kettlery in Piplod, which is a tea bar that offers a wide selection of teas from around the world. Another great option is Bhai Bhai Omelette Centre in Adajan, which is famous for its delicious omelettes and other egg dishes.\n",
        "\n",
        "If you're looking for a more upscale dining experience, head to The Belgian Waffle Co. in Vesu, which offers a variety of sweet and savory waffles, as well as a selection of other dishes. Another popular fine-dining option is Spice Villa in Athwa, which serves authentic North Indian cuisine in a luxurious setting.\n",
        "\n",
        "For those who enjoy a night out, Surat has a growing pub scene. One of the most popular spots is The Beer Cafe in Dumas, which offers a great selection of beers and a lively atmosphere. Another great option is Pepperazzi in Vesu, which has a wide range of cocktails and a trendy atmosphere.\n",
        "\n",
        "Finally, for those who want to enjoy a meal with a view, head to The Riverfront Terrace in Adajan, which offers stunning views of the Tapi River and delicious food. Another great option is the rooftop bar at the Grand Bhagwati hotel, which offers a great selection of drinks and a beautiful view of the city.'''"
      ],
      "metadata": {
        "id": "dlqMCJ0gRBwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mumbai = \"\"\"Mumbai is a foodie's paradise and has a plethora of dining and nightlife options. For those looking for a great meal, one must-visit place is the Bombay Canteen in Lower Parel. Here, you can indulge in modern Indian cuisine with a twist, and their cocktails are also a must-try.\n",
        "\n",
        "Another popular restaurant is The Table in Colaba, which offers a fusion of Indian and international flavors. Their small plates and sharing platters are perfect for trying a variety of dishes. If you're in the mood for some seafood, head to Trishna in Fort, which is famous for their butter garlic crab.\n",
        "\n",
        "Mumbai is also known for its nightlife, and there are several great pubs and bars to explore. The Woodside Inn in Andheri is a popular spot that offers a range of beers, cocktails, and food. For those who enjoy live music, Hard Rock Cafe in Worli is a must-visit spot.\n",
        "\n",
        "If you're looking for a unique experience, try the Dome in Marine Drive, which offers stunning views of the Arabian Sea and the Mumbai skyline. They serve a range of cocktails and snacks, and the sunset here is truly breathtaking.\n",
        "\n",
        "Overall, Mumbai has a diverse range of dining and nightlife options, so there's something for everyone.\"\"\""
      ],
      "metadata": {
        "id": "-15rZhnDRAPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kolkata = \"\"\"Kolkata is known for its rich food culture, and there are plenty of great dining and nightlife options to explore. If you're looking for authentic Bengali cuisine, Oh! Calcutta in Salt Lake is a must-visit spot. They offer a range of traditional dishes like fish curry and rice, as well as fusion options that combine Bengali flavors with other cuisines.\n",
        "\n",
        "For those looking for a unique dining experience, The Biker's Cafe in Elgin Road is a popular spot. The restaurant is themed around motorcycles, and they serve a range of dishes from around the world, including burgers, pizzas, and wraps.\n",
        "\n",
        "Kolkata is also home to some great pubs and bars. One popular spot is Monkey Bar in Camac Street, which has a laid-back vibe and a range of cocktails and pub food. For those who enjoy craft beer, The Grid in Topsia is a great option, with a range of brews on tap and delicious snacks to accompany them.\n",
        "\n",
        "For a more upscale experience, head to the Westin Hotel in Rajarhat, where you'll find the Seasonal Tastes restaurant and the Mix bar. Both offer stunning views of the city, and the food and drinks are top-notch.\n",
        "\n",
        "Overall, Kolkata has a range of dining and nightlife options to suit all tastes and budgets, so make sure to explore the city's culinary scene while you're there.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "QEYoCvcuRd_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o3eItBf8u4a2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}