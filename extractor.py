# -*- coding: utf-8 -*-
"""class_final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/ChaitaliV/Splurge/blob/main/location_extractor/class_final.ipynb
"""

from google.colab import drive
drive.mount('/content/drive')

import torch
import torch.nn as nn
import numpy as np
import os
import openai
import re
from transformers import BertTokenizer, BertForTokenClassification
from keras_preprocessing.sequence import pad_sequences
from sklearn.model_selection import train_test_split
from torch.nn.utils.rnn import pad_sequence
from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset
from transformers import AdamW, get_linear_schedule_with_warmup
from tqdm import tqdm, trange
import requests

tokenizer = BertTokenizer.from_pretrained('bert-base-cased')
model = torch.load(r'/content/drive/MyDrive/BERT_text.pt')
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
base_url = "https://maps.googleapis.com/maps/api/place/findplacefromtext/json"
api_key = "AIzaSyCU7kaDfhZIM4bbJVujlGlhdXphUPke1yY"
engine = "text-davinci-002"
MAX_LEN = 512

class LocationExtractor:
    def __init__(self, sent, city):
        self.device = device
        self.tokenizer = tokenizer
        self.model = model
        self.model.to(self.device)
        self.city = city
        self.sent = sent
        self.categories = ['Restaurant', 'Cafe', 'House', 'Barbecue', 'Bar', 'Pub', 'Palace', 'Kitchen', 'Club', 'Bakery', 'Shop', 'Room', 'Shack', 'Garden', 'Factory', 'Queen', 'Street','Castle', 'Mall', 'Park', 'Palace', 'Temple', 'Masjid', 'Dargah', 'Avenue', 'Gallery', 'Museum', 'Garden', 'Hotel', 'Lake', 'Fort', 'Beach', 'Mandir', 'Hill', 'Bhavan', 'Nation', 'World', 'Center','Pavilion', 'Bistro']

    def clean_string(self, lst, sent):
        l = []
        for ele in lst:
            if ele == ' ' or ele == '':
                pass
            else:
                l.append(ele)
        return l

    def add_suffix(self, p, sent):
        match = re.search(p, sent)
        if match:
            for category in self.categories:
                if match.end() < len(sent) and sent[match.end():].lower().startswith(category.lower()):
                    l = match.group() + '' + category
                    return l
                    break
            return match.group()
        else:
            return p
        
    def add_next_word(self, p, sent):
        match = re.search(p, sent)
        if match:
            s = sent[match.end():]
            try: 
              if (s[0] == '' or ' '):
                p = p + ' ' + s[1]
              else:
                p = p+' '+s[0]
            except:
              pass
        return p

    def extract_location(self, sent):
        true_label = []
        tokenized_sentence = self.tokenizer.encode(sent)
        input_ids = torch.tensor([tokenized_sentence]).to(self.device)
        with torch.no_grad():
            output = self.model(input_ids)
        label_indices = np.argmax(output[0].to('cpu').numpy(), axis=2)
        tokens = self.tokenizer.convert_ids_to_tokens(input_ids.to('cpu').numpy()[0])
        new_tokens, new_labels = [], []
        for token, label_idx in zip(tokens, label_indices[0]):
            if token.startswith("##"):
                new_tokens[-1] = new_tokens[-1] + token[2:]
            else:
                new_labels.append(label_idx)
                new_tokens.append(token)
        for token, label in zip(new_tokens, new_labels):
            if (label == 3):
                true_label.append(token)
            else:
                true_label.append('#')
        label = " ".join(true_label)
        label = label.replace(" ' s","'s")
        lst = label.split('#')
        p = self.clean_string(lst, sent)
        final_lst = []
        for ele in p:
            final_lst.append(self.add_suffix(ele, sent))
        list_2 = []
        for ele in final_lst:
            list_2.append(self.add_next_word(ele,sent))
        return list(filter(None, list_2))

    def multiline_data(self, text):
        text = text.replace('\n','.')
        names = []
        lst = text.split(".")
        for sent in lst:
            names.append(self.extract_location(sent))
        data = list(filter(None, names))
        l = []
        for place_list in data:
            for i in place_list:
                l.append(i + ', ' + self.city)
        return l

class PlaceFinder:
    def __init__(self, data):
        self.base_url = base_url
        self.api_key = api_key
        self.data = data

    def fetch_place_details(self,place_name):
      # Set up the parameters for the API request
      global result
      params = {
          'key': self.api_key,
          'input': place_name,
          'inputtype': 'textquery',
          'fields': 'place_id,name,formatted_address,rating,opening_hours,geometry,photos,types'
      }

      # Send the API request
      response = requests.get(self.base_url, params=params).json()

      # Check if the response contains any results
      if response['status'] == 'ZERO_RESULTS':
          result = ''
      else:
          result = response['candidates'][0]
          # Get the place ID of the first result (assuming it is the correct restaurant)
          place_id = response['candidates'][0]['place_id']

          # Make a request to the Places Details API to fetch the phone number
          details_url = f'https://maps.googleapis.com/maps/api/place/details/json?place_id={place_id}&fields=international_phone_number&key={api_key}'
          details_response = requests.get(details_url).json()

          # Extract the relevant details from the API response
          details = {}
          details['Name']= result['name']
          details['Address']= result['formatted_address']
          details['Rating'] = result.get('rating', 'N/A')
          details['Opening Hours'] =  result.get('opening_hours', 'N/A')
          details['Location']= result['geometry']['location']
          details['Types'] = result.get('types', 'N/A')[0]

          details['Phone'] = details_response['result'].get('international_phone_number', 'N/A')
          photos = []
          photo_references = result.get('photos', [])
          for photo_reference in photo_references:
              photo_url = f"https://maps.googleapis.com/maps/api/place/photo?maxwidth=400&photoreference={photo_reference['photo_reference']}&key={api_key}"
              photos.append(photo_url)
          details['Photos'] = photos

          return details

    
    def get_places_data(self):
        data = []
        for ele in self.data:
            data.append(self.fetch_place_details(ele))
        return data
    
    
   
class PlaceDescriptionGenerator:
    def __init__(self, openai_key):
        self.openai_key = openai_key
        self.engine = engine
        openai.api_key = openai_key
        
        
    def get_description(self,place_name):
      # Set the prompt for the API
      prompt = """Get a 200 characters, accurate description about the """ + place_name+ """ from the internet,
      you can use google description about the place or some other website to get description about this place. Description 
      should include place type, Ambience, what it provides, speciality, etc. Please generate accurate description.
      """
      # Generate a response to the prompt
      response = openai.Completion.create(
          engine=self.engine,
          prompt=prompt,
          max_tokens=1024,
          n=1,
          stop=None,
          temperature=0.7,
      )

      # Extract the generated text from the response
      message = response.choices[0].text.strip()
      
      # Split the message into the description and tags
      place_tokens = place_name.split(',')
      for token in place_tokens:
          message1 = message.replace(token, '')
      return message1, message
    
    def get_tags(self,description):
      prompt = """
      Generate only three tags,each tag should not be more than 2 words long, from the """+description+""", Note that out of three tags, one tag should be about place
      type, for example is it cafe, restaurant, shopping place, spa, etc. second tag should be cuisine or another category 
      that describes the place, for example if it is Italian cafe, tag should be Italian, If it is museaum, the tag 
      should be art & History, etc. third tag should be something creative about the place, For example, if it is a roof-top 
      cafe third tag can be rooftop, If it is a shopping street famous for night-life, third tag should be night-life.
      if it is site-seeing, third tag can be tourist attraction, etc. Note that each tag SHOULD NOT be more than 2
      words long."""
      # Generate a response to the prompt
      response = openai.Completion.create(
          engine=engine,
          prompt=prompt,
          max_tokens=32,
          n=1,
          stop=None,
          temperature=0.7,
      )

      # Extract the generated text from the response
      message = response.choices[0].text.strip()
      words_to_remove = ['Tag','Tags','input','tags','tag','Input','var','Place','place','type','Type','CODE','enter','YOUR  HERE','Output','here','list of','three','append']
      message = message.replace('\n',',')
      clean_text = re.sub("[^A-Za-z,']+", ' ', message)
      for word in words_to_remove:
          clean_text = clean_text.replace(word,'')
      return clean_text
      
    def list_tag_data(self,data):
      all_data = []
      for place in data:
        info = {}
        des = self.get_description(place)
        info['Tags'] = self.get_tags(des)
        info['Description'] = des
        all_data.append(info)
      return all_data
