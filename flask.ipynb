{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChaitaliV/Location-Extractor/blob/main/flask.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ChaitaliV/Location-Extractor\n",
        "!pip install -r Location-Extractor/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7WoZPmsmlnd",
        "outputId": "1561797d-f247-44a3-db01-bc3fda5d16eb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Location-Extractor'...\n",
            "remote: Enumerating objects: 403, done.\u001b[K\n",
            "remote: Counting objects: 100% (40/40), done.\u001b[K\n",
            "remote: Compressing objects: 100% (40/40), done.\u001b[K\n",
            "remote: Total 403 (delta 14), reused 0 (delta 0), pack-reused 363\u001b[K\n",
            "Receiving objects: 100% (403/403), 7.00 MiB | 24.22 MiB/s, done.\n",
            "Resolving deltas: 100% (226/226), done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting flask-ngrok==0.0.25 (from -r Location-Extractor/requirements.txt (line 1))\n",
            "  Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n",
            "Collecting pyngrok==5.1.0 (from -r Location-Extractor/requirements.txt (line 2))\n",
            "  Downloading pyngrok-5.1.0.tar.gz (745 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m745.3/745.3 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytorch-pretrained-bert==0.6.2 (from -r Location-Extractor/requirements.txt (line 3))\n",
            "  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytorch-nlp==0.5.0 (from -r Location-Extractor/requirements.txt (line 4))\n",
            "  Downloading pytorch_nlp-0.5.0-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.1/90.1 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers==4.28.1 (from -r Location-Extractor/requirements.txt (line 5))\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras-preprocessing==1.1.2 (from -r Location-Extractor/requirements.txt (line 6))\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai==0.10.2 (from -r Location-Extractor/requirements.txt (line 7))\n",
            "  Downloading openai-0.10.2.tar.gz (156 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.7/156.7 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pymongo==4.3.3 (from -r Location-Extractor/requirements.txt (line 8))\n",
            "  Downloading pymongo-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (492 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m492.9/492.9 kB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.10/dist-packages (from flask-ngrok==0.0.25->-r Location-Extractor/requirements.txt (line 1)) (2.2.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from flask-ngrok==0.0.25->-r Location-Extractor/requirements.txt (line 1)) (2.27.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyngrok==5.1.0->-r Location-Extractor/requirements.txt (line 2)) (6.0)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-bert==0.6.2->-r Location-Extractor/requirements.txt (line 3)) (2.0.1+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-bert==0.6.2->-r Location-Extractor/requirements.txt (line 3)) (1.22.4)\n",
            "Collecting boto3 (from pytorch-pretrained-bert==0.6.2->-r Location-Extractor/requirements.txt (line 3))\n",
            "  Downloading boto3-1.26.137-py3-none-any.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.6/135.6 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-bert==0.6.2->-r Location-Extractor/requirements.txt (line 3)) (4.65.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-bert==0.6.2->-r Location-Extractor/requirements.txt (line 3)) (2022.10.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1->-r Location-Extractor/requirements.txt (line 5)) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0 (from transformers==4.28.1->-r Location-Extractor/requirements.txt (line 5))\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1->-r Location-Extractor/requirements.txt (line 5)) (23.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.28.1->-r Location-Extractor/requirements.txt (line 5))\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m100.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from keras-preprocessing==1.1.2->-r Location-Extractor/requirements.txt (line 6)) (1.16.0)\n",
            "Requirement already satisfied: pandas>=1.2.3 in /usr/local/lib/python3.10/dist-packages (from openai==0.10.2->-r Location-Extractor/requirements.txt (line 7)) (1.5.3)\n",
            "Collecting pandas-stubs>=1.1.0.11 (from openai==0.10.2->-r Location-Extractor/requirements.txt (line 7))\n",
            "  Downloading pandas_stubs-2.0.1.230501-py3-none-any.whl (151 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.2/151.2 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: openpyxl>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from openai==0.10.2->-r Location-Extractor/requirements.txt (line 7)) (3.0.10)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo==4.3.3->-r Location-Extractor/requirements.txt (line 8))\n",
            "  Downloading dnspython-2.3.0-py3-none-any.whl (283 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok==0.0.25->-r Location-Extractor/requirements.txt (line 1)) (2.3.0)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok==0.0.25->-r Location-Extractor/requirements.txt (line 1)) (3.1.2)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok==0.0.25->-r Location-Extractor/requirements.txt (line 1)) (2.1.2)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok==0.0.25->-r Location-Extractor/requirements.txt (line 1)) (8.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.1->-r Location-Extractor/requirements.txt (line 5)) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.1->-r Location-Extractor/requirements.txt (line 5)) (4.5.0)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl>=3.0.7->openai==0.10.2->-r Location-Extractor/requirements.txt (line 7)) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.3->openai==0.10.2->-r Location-Extractor/requirements.txt (line 7)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.3->openai==0.10.2->-r Location-Extractor/requirements.txt (line 7)) (2022.7.1)\n",
            "Collecting types-pytz>=2022.1.1 (from pandas-stubs>=1.1.0.11->openai==0.10.2->-r Location-Extractor/requirements.txt (line 7))\n",
            "  Downloading types_pytz-2023.3.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok==0.0.25->-r Location-Extractor/requirements.txt (line 1)) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok==0.0.25->-r Location-Extractor/requirements.txt (line 1)) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok==0.0.25->-r Location-Extractor/requirements.txt (line 1)) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok==0.0.25->-r Location-Extractor/requirements.txt (line 1)) (3.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert==0.6.2->-r Location-Extractor/requirements.txt (line 3)) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert==0.6.2->-r Location-Extractor/requirements.txt (line 3)) (3.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert==0.6.2->-r Location-Extractor/requirements.txt (line 3)) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=0.4.1->pytorch-pretrained-bert==0.6.2->-r Location-Extractor/requirements.txt (line 3)) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=0.4.1->pytorch-pretrained-bert==0.6.2->-r Location-Extractor/requirements.txt (line 3)) (16.0.5)\n",
            "Collecting botocore<1.30.0,>=1.29.137 (from boto3->pytorch-pretrained-bert==0.6.2->-r Location-Extractor/requirements.txt (line 3))\n",
            "  Downloading botocore-1.29.137-py3-none-any.whl (10.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m90.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3->pytorch-pretrained-bert==0.6.2->-r Location-Extractor/requirements.txt (line 3))\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0 (from boto3->pytorch-pretrained-bert==0.6.2->-r Location-Extractor/requirements.txt (line 3))\n",
            "  Downloading s3transfer-0.6.1-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->Flask>=0.8->flask-ngrok==0.0.25->-r Location-Extractor/requirements.txt (line 1)) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=0.4.1->pytorch-pretrained-bert==0.6.2->-r Location-Extractor/requirements.txt (line 3)) (1.3.0)\n",
            "Building wheels for collected packages: pyngrok, openai\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyngrok: filename=pyngrok-5.1.0-py3-none-any.whl size=18985 sha256=0f6ed2bfd1a9f23b0abea59ce5b5425e32c941789f6985487d83a15201450b3e\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/46/5e/496d5251f1530ae9988fcd3aad34ad7a46de82d9cc0f61cad6\n",
            "  Building wheel for openai (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai: filename=openai-0.10.2-py3-none-any.whl size=168332 sha256=0014a83fde2a819f27223d57bbfc08b0665aa12a3c9dc16aaac8d5ace58c9830\n",
            "  Stored in directory: /root/.cache/pip/wheels/70/39/75/a154ffba6d11ba573b4687fd85b5fab8700cfe0a28dc4aad5a\n",
            "Successfully built pyngrok openai\n",
            "Installing collected packages: types-pytz, tokenizers, pytorch-nlp, pyngrok, pandas-stubs, keras-preprocessing, jmespath, dnspython, pymongo, huggingface-hub, botocore, transformers, s3transfer, openai, flask-ngrok, boto3, pytorch-pretrained-bert\n",
            "Successfully installed boto3-1.26.137 botocore-1.29.137 dnspython-2.3.0 flask-ngrok-0.0.25 huggingface-hub-0.14.1 jmespath-1.0.1 keras-preprocessing-1.1.2 openai-0.10.2 pandas-stubs-2.0.1.230501 pymongo-4.3.3 pyngrok-5.1.0 pytorch-nlp-0.5.0 pytorch-pretrained-bert-0.6.2 s3transfer-0.6.1 tokenizers-0.13.3 transformers-4.28.1 types-pytz-2023.3.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok authtoken 2Oi7yxSmNSVx99JN4GB0VOJ65CL_QXcR2c9EqSaq82WLo5b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQayf8N7dCvt",
        "outputId": "4ced4ef0-6cb8-4e02-85fa-ed437fcaca36"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask,render_template,request,jsonify\n",
        "import sys\n",
        "import pandas as pd\n",
        "from pymongo import MongoClient\n",
        "from flask_ngrok import run_with_ngrok\n",
        "sys.path.append('Location-Extractor')\n",
        "import json"
      ],
      "metadata": {
        "id": "uKfMxAmecbk1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openaikey = \"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\" "
      ],
      "metadata": {
        "id": "ZKPsy8osWJwr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_url = \"https://maps.googleapis.com/maps/api/place/findplacefromtext/json\"\n",
        "api_key = \"AIzaSyCU7kaDfhZIM4bbJVujlGlhdXphUPke1yY\""
      ],
      "metadata": {
        "id": "LVoPc6ycw7l5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from extractor import PlaceFinder, PlaceDescriptionGenerator, LocationExtractor, PlaceTagger"
      ],
      "metadata": {
        "id": "ur_-0_dZb7u3",
        "outputId": "88ab8309-8ed1-4277-85a8-472315ee9fba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211,
          "referenced_widgets": [
            "8a6fbcff3801441c9cae50779be35f34",
            "35da557e99d4439781e284fd827c08fc",
            "605d2478f0c94526adb042a2df43b9ee",
            "4cc0d373da2b4a5e8f43d486b3f58c05"
          ]
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8a6fbcff3801441c9cae50779be35f34",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "35da557e99d4439781e284fd827c08fc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "605d2478f0c94526adb042a2df43b9ee",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4cc0d373da2b4a5e8f43d486b3f58c05",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/436M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_all_data(sentence,city, key):\n",
        "  location_extractor = LocationExtractor(sentence, city)\n",
        "  location_data = location_extractor.multiline_data(sentence)\n",
        "\n",
        "  place_finder = PlaceFinder(list(set(location_data)))\n",
        "  ex_places = place_finder.get_places_data()\n",
        "  df = pd.DataFrame(ex_places)\n",
        "  df = df.drop_duplicates(subset = ['Name'])\n",
        "  df.reset_index(inplace=True)\n",
        "  place_description = PlaceDescriptionGenerator(openai_key = openaikey)\n",
        "  try:\n",
        "    places = df['Name'][:] + city\n",
        "  except:\n",
        "    return None\n",
        "  location = df['Location'][:]\n",
        "  lon = []\n",
        "  lat = []\n",
        "  timing = []\n",
        "  for loc in location:\n",
        "    lon.append(loc['lng'])\n",
        "    lat.append(loc['lat'])\n",
        "  tags = []\n",
        "  description = []\n",
        "  for place in places:\n",
        "    try:\n",
        "      des = place_description.get_description(place)\n",
        "      description.append(des.replace('\\n',''))\n",
        "    except:\n",
        "      description.append('')\n",
        "  df2 = pd.read_csv('Location-Extractor/Data/tag_name_list.csv')\n",
        "  place_tagger = PlaceTagger(df2)\n",
        "  all_tags = place_tagger.all_tags(df)\n",
        "  df['Tags'] = all_tags\n",
        "  df['Description'] = description\n",
        "  df['Longitude'] = lon\n",
        "  df['Latitude'] = lat\n",
        "  #df['Opening Hours'] = timing\n",
        "  return df"
      ],
      "metadata": {
        "id": "ZpxNkh_4V7NI"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"Ahmedabad, the largest city in the Indian state of Gujarat, offers a variety of hangout places that cater to different interests and preferences. Here are five hangout places in Ahmedabad that you can explore:\n",
        "\n",
        "1. Sabarmati Riverfront: The Sabarmati Riverfront is a popular hangout spot that offers a refreshing escape from the city's hustle and bustle. You can enjoy a leisurely walk or cycle along the riverfront promenade, relax in the well-maintained gardens, or indulge in boat rides on the Sabarmati River. The serene atmosphere and beautiful views make it an ideal place to unwind.\n",
        "\n",
        "2. Kankaria Lake: Kankaria Lake is a picturesque lake located in the heart of Ahmedabad. It features a circular promenade, offering various recreational activities such as toy train rides, balloon rides, and boating. You can also explore the sprawling Kankaria Zoo nearby or enjoy the vibrant light and sound show in the evenings.\n",
        "\n",
        "3. Manek Chowk: Manek Chowk is a bustling night market and a food lover's paradise in Ahmedabad. It comes alive after sunset and offers a wide range of street food options, including mouth-watering Gujarati snacks, pav bhaji, dosas, and delectable ice creams. It's a vibrant and lively place to satisfy your taste buds and experience the local culinary delights.\n",
        "\n",
        "4. Law Garden Night Market: Law Garden Night Market is a famous open-air street market renowned for its handicrafts, traditional garments, and accessories. It is an excellent place to shop for colorful ethnic attire, intricate bandhani (tie-dye) fabrics, embroidered textiles, jewelry, and other handicrafts. You can also savor delicious street food while exploring the market.\n",
        "\n",
        "5. Adalaj Stepwell: Located on the outskirts of Ahmedabad, the Adalaj Stepwell is a historical marvel and a serene hangout spot. This intricately carved stepwell showcases stunning architectural design and serves as a peaceful retreat. The cool and tranquil ambiance makes it an ideal place for relaxation, meditation, and capturing beautiful photographs.\n",
        "\n",
        "These are just a few of the many hangout places that Ahmedabad has to offer. Whether you seek historical sites, nature spots, cultural experiences, or delicious food, Ahmedabad has something to cater to everyone's interests.\"\"\"\n",
        "city = 'Ahemdabad'\n",
        "places_df = fetch_all_data(text,city,openaikey)\n",
        "records = places_df.to_dict(orient='records')\n",
        "places_json = json.dumps(records)"
      ],
      "metadata": {
        "id": "Al4mHMjUcRix"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zjEhAIUenQp8"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "app = Flask(__name__, template_folder='Location-Extractor/templates',static_folder='Location-Extractor/static')\n",
        "run_with_ngrok(app)   \n",
        "\n",
        "@app.route(\"/\",methods=['GET','POST'])\n",
        "def home():\n",
        "  #return render_template('mappage.html',  places_json=places_json, city_name = 'Ahemdabad')\n",
        "  return render_template('frontpage.html')\n",
        "\n",
        "@app.route('/process',methods=['GET','POST'])\n",
        "def data():\n",
        "    sentence = request.form['paragraph']\n",
        "    city = request.form['city']\n",
        "    places_df = fetch_all_data(sentence,city,openaikey)\n",
        "    print(len(places_df))\n",
        "    records = places_df.to_dict(orient='records')\n",
        "    places_json = json.dumps(records)\n",
        "    # Perform any necessary processing on the paragraph variable here\n",
        "    return render_template('mappage.html',  places_json=places_json,city_name = city)\n",
        "\n",
        "app.run() "
      ],
      "metadata": {
        "id": "qGssCw9vjs2n",
        "outputId": "14f4bdca-0cae-478e-ef33-278d5102cb1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Running on http://f6a3-34-75-51-69.ngrok-free.app\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [22/May/2023 23:37:33] \"GET / HTTP/1.1\" 200 -\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MkC6LXzNl-Uv"
      },
      "execution_count": 85,
      "outputs": []
    }
  ]
}