{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pp0SkF5naiOO",
        "outputId": "a407dda7-2d4c-4341-b477-e9e122190806"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "!pip install pytorch-pretrained-bert pytorch-nlp\n",
        "!pip install -q transformers\n",
        "!pip install Keras-Preprocessing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFKiySgsxjWa",
        "outputId": "325601e2-d645-49c7-adc3-f66159f926ce"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.6-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Collecting aiohttp (from openai)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->openai)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->openai)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->openai)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->openai)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->openai)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.6 yarl-1.9.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch-pretrained-bert\n",
            "  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytorch-nlp\n",
            "  Downloading pytorch_nlp-0.5.0-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.1/90.1 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-bert) (2.0.1+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-bert) (1.22.4)\n",
            "Collecting boto3 (from pytorch-pretrained-bert)\n",
            "  Downloading boto3-1.26.135-py3-none-any.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.6/135.6 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-bert) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-bert) (4.65.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-bert) (2022.10.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=0.4.1->pytorch-pretrained-bert) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=0.4.1->pytorch-pretrained-bert) (16.0.5)\n",
            "Collecting botocore<1.30.0,>=1.29.135 (from boto3->pytorch-pretrained-bert)\n",
            "  Downloading botocore-1.29.135-py3-none-any.whl (10.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m83.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3->pytorch-pretrained-bert)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0 (from boto3->pytorch-pretrained-bert)\n",
            "  Downloading s3transfer-0.6.1-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-pretrained-bert) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-pretrained-bert) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-pretrained-bert) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-pretrained-bert) (3.4)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.30.0,>=1.29.135->boto3->pytorch-pretrained-bert) (2.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=0.4.1->pytorch-pretrained-bert) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=0.4.1->pytorch-pretrained-bert) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.30.0,>=1.29.135->boto3->pytorch-pretrained-bert) (1.16.0)\n",
            "Installing collected packages: pytorch-nlp, jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert\n",
            "Successfully installed boto3-1.26.135 botocore-1.29.135 jmespath-1.0.1 pytorch-nlp-0.5.0 pytorch-pretrained-bert-0.6.2 s3transfer-0.6.1\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting Keras-Preprocessing\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from Keras-Preprocessing) (1.22.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from Keras-Preprocessing) (1.16.0)\n",
            "Installing collected packages: Keras-Preprocessing\n",
            "Successfully installed Keras-Preprocessing-1.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from IPython.display import Image\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer\n",
        "from transformers import AdamW, BertForTokenClassification, get_linear_schedule_with_warmup\n",
        "from tqdm import tqdm, trange\n",
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "import re\n",
        "from transformers import BertModel, BertConfig\n",
        "import requests"
      ],
      "metadata": {
        "id": "68Ks_Kt-ayHG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "checkpoint = torch.load('/content/drive/MyDrive/BERT_text_dict.pth',map_location=torch.device('cpu'))\n",
        "configuration = BertConfig()\n",
        "model = BertModel(configuration)\n",
        "model = BertForTokenClassification.from_pretrained(\"bert-base-cased\",num_labels=1882,\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False)\n",
        "model.load_state_dict({k.replace('module.', ''): v for k, v in checkpoint.items()})"
      ],
      "metadata": {
        "id": "zEmNCywA7A-B",
        "outputId": "bc83623d-69bc-4e95-e5de-80234938ad64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cpu'"
      ],
      "metadata": {
        "id": "yLkuuBnE7XOS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(torch.device('cpu'))\n",
        "base_url = \"https://maps.googleapis.com/maps/api/place/findplacefromtext/json\"\n",
        "api_key = \"AIzaSyCU7kaDfhZIM4bbJVujlGlhdXphUPke1yY\"\n",
        "MAX_LEN = 512"
      ],
      "metadata": {
        "id": "eIc7jAM_cKfa"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LocationExtractor:\n",
        "    def __init__(self, sent, city):\n",
        "        self.device = device\n",
        "        self.tokenizer = tokenizer\n",
        "        self.model = model\n",
        "        self.model.to(self.device)\n",
        "        self.sent = sent\n",
        "        self.city = city\n",
        "        self.categories = ['Restaurant', 'Cafe', 'House', 'Barbecue', 'Bar', 'Pub', 'Palace', 'Kitchen', 'Club', 'Bakery', 'Shop', 'Room', 'Shack', 'Garden', 'Factory', 'Queen']\n",
        "\n",
        "    def clean_string(self, lst, sent):\n",
        "        l = []\n",
        "        for ele in lst:\n",
        "            if ele == ' ' or ele == '':\n",
        "                pass\n",
        "            else:\n",
        "                l.append(ele)\n",
        "        return l\n",
        "\n",
        "    def add_suffix(self, p, sent):\n",
        "        match = re.search(p, sent)\n",
        "        if match:\n",
        "            for category in self.categories:\n",
        "                if match.end() < len(sent) and sent[match.end():].lower().startswith(category.lower()):\n",
        "                    l = match.group() + '' + category\n",
        "                    return l\n",
        "                    break\n",
        "            return match.group()\n",
        "        else:\n",
        "            return p\n",
        "\n",
        "    def extract_location(self, sent):\n",
        "        true_label = []\n",
        "        tokenized_sentence = self.tokenizer.encode(sent)\n",
        "        input_ids = torch.tensor([tokenized_sentence]).to(self.device)\n",
        "        with torch.no_grad():\n",
        "            output = self.model(input_ids)\n",
        "        label_indices = np.argmax(output[0].to('cpu').numpy(), axis=2)\n",
        "        tokens = self.tokenizer.convert_ids_to_tokens(input_ids.to('cpu').numpy()[0])\n",
        "        new_tokens, new_labels = [], []\n",
        "        for token, label_idx in zip(tokens, label_indices[0]):\n",
        "            if token.startswith(\"##\"):\n",
        "                new_tokens[-1] = new_tokens[-1] + token[2:]\n",
        "            else:\n",
        "                new_labels.append(label_idx)\n",
        "                new_tokens.append(token)\n",
        "        for token, label in zip(new_tokens, new_labels):\n",
        "            if (label == 3):\n",
        "                true_label.append(token)\n",
        "            else:\n",
        "                true_label.append('#')\n",
        "        label = \" \".join(true_label)\n",
        "        label = label.replace(\" ' s\",\"'s\")\n",
        "        lst = label.split('#')\n",
        "        p = self.clean_string(lst, sent)\n",
        "        final_lst = []\n",
        "        for ele in p:\n",
        "            final_lst.append(self.add_suffix(ele, sent))\n",
        "        return list(filter(None, final_lst))\n",
        "\n",
        "    def multiline_data(self, text):\n",
        "        names = []\n",
        "        lst = text.split(\".\")\n",
        "        for sent in lst:\n",
        "            names.append(self.extract_location(sent))\n",
        "        data = list(filter(None, names))\n",
        "        l = []\n",
        "        for place_list in data:\n",
        "            for i in place_list:\n",
        "                l.append(i + ', ' + self.city)\n",
        "        return l\n"
      ],
      "metadata": {
        "id": "SYCKnDmhVl5h"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"I went to Paris and visited the Eiffel Tower and then went to the Chocolate room cafe. We also went to the Lovre \"\n",
        "location_extractor = LocationExtractor(sentence, 'Paris')\n",
        "data = location_extractor.multiline_data(sentence)"
      ],
      "metadata": {
        "id": "ijG9tGhtu-W6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "p9FzdIbP14Uo",
        "outputId": "1019b5d0-64bc-484d-d5c5-f4519cfc9c7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' Eiffel , Paris', ' Chocolate room Cafe, Paris', ' Lovre , Paris']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PlaceFinder:\n",
        "    def __init__(self, data):\n",
        "        self.base_url = base_url\n",
        "        self.api_key = api_key\n",
        "        self.data = data\n",
        "\n",
        "    def fetch_place_details(self,place_name):\n",
        "      # Set up the parameters for the API request\n",
        "      global result\n",
        "      params = {\n",
        "          'key': self.api_key,\n",
        "          'input': place_name,\n",
        "          'inputtype': 'textquery',\n",
        "          'fields': 'place_id,name,formatted_address,rating,opening_hours,geometry,photos'\n",
        "      }\n",
        "\n",
        "      # Send the API request\n",
        "      response = requests.get(self.base_url, params=params).json()\n",
        "\n",
        "      # Check if the response contains any results\n",
        "      if response['status'] == 'ZERO_RESULTS':\n",
        "          result = ''\n",
        "      else:\n",
        "          result = response['candidates'][0]\n",
        "          # Get the place ID of the first result (assuming it is the correct restaurant)\n",
        "          place_id = response['candidates'][0]['place_id']\n",
        "\n",
        "          # Make a request to the Places Details API to fetch the phone number\n",
        "          details_url = f'https://maps.googleapis.com/maps/api/place/details/json?place_id={place_id}&fields=international_phone_number&key={api_key}'\n",
        "          details_response = requests.get(details_url).json()\n",
        "\n",
        "          # Extract the relevant details from the API response\n",
        "          details = {}\n",
        "          details['Name']= result['name']\n",
        "          details['Address']= result['formatted_address']\n",
        "          details['Rating'] = result.get('rating', 'N/A')\n",
        "          details['Opening Hours'] =  result.get('opening_hours', 'N/A')\n",
        "          details['Location']= result['geometry']['location']\n",
        "\n",
        "          details['Phone'] = details_response['result'].get('international_phone_number', 'N/A')\n",
        "          photo_reference = response['candidates'][0].get('photos', None)\n",
        "          if photo_reference:\n",
        "              photo_url = f\"https://maps.googleapis.com/maps/api/place/photo?maxwidth=400&photoreference={photo_reference[0]['photo_reference']}&key={api_key}\"\n",
        "              details['Photo'] = photo_url\n",
        "          else:\n",
        "              details['Photo'] = 'N/A'\n",
        "\n",
        "          return details\n",
        "\n",
        "    \n",
        "    def get_places_data(self):\n",
        "        data = []\n",
        "        for ele in self.data:\n",
        "            data.append(self.fetch_place_details(ele))\n",
        "        return data\n",
        "    \n",
        "    \n"
      ],
      "metadata": {
        "id": "k1ej7OPMzm1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "place_finder = PlaceFinder(data)\n",
        "details = place_finder.get_places_data()"
      ],
      "metadata": {
        "id": "IkD683t2w-9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "details"
      ],
      "metadata": {
        "id": "p75i71pp2mUt",
        "outputId": "b62a9ab1-5909-43ca-eebe-6c3407815f6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'Name': 'Eiffel Tower',\n",
              "  'Address': 'Champ de Mars, 5 Av. Anatole France, 75007 Paris, France',\n",
              "  'Rating': 4.6,\n",
              "  'Opening Hours': {'open_now': True},\n",
              "  'Location': {'lat': 48.85837009999999, 'lng': 2.2944813},\n",
              "  'Phone': 'N/A',\n",
              "  'Photo': 'https://maps.googleapis.com/maps/api/place/photo?maxwidth=400&photoreference=AUjq9jmy9aVvlGoqgIAHpZP5c8nwl6bEEvAk3Wi3gbYCJcNqKUNdLjlOa-nz3aZr80a6y-aFN3kXi7ZQXbmZ1V20kPrY3OPG5uaZVIq98TIh2nLwtoXZaSacQBGq86FDjaudbZDYxxbJ3loiu32fKIXxKvuomh5FEYphTVKCVOr5QYALPTwe&key=AIzaSyCU7kaDfhZIM4bbJVujlGlhdXphUPke1yY'},\n",
              " {'Name': 'Hoct & Loca',\n",
              "  'Address': '99 Rue de la Verrerie, 75004 Paris, France',\n",
              "  'Rating': 4.2,\n",
              "  'Opening Hours': {'open_now': True},\n",
              "  'Location': {'lat': 48.858863, 'lng': 2.350273},\n",
              "  'Phone': '+33 1 45 32 12 09',\n",
              "  'Photo': 'https://maps.googleapis.com/maps/api/place/photo?maxwidth=400&photoreference=AUjq9jnvoD_mifWtMyuNfR8kyKtWY2RduuLfa-2miyqgDguQ1m4ekZEOuorwXrGmIT8UHqdHT701XN1FdHbIayt2hV6Kaoq-hIDMB-RfxMmXFjoAMh-dVjeC2GXDtzlflC_JeVnqEG-62gINDcCyYRJL_dhv-qVFC8ghFJ9E7zes19j4Aq3Y&key=AIzaSyCU7kaDfhZIM4bbJVujlGlhdXphUPke1yY'},\n",
              " {'Name': 'Louvre Museum',\n",
              "  'Address': '75001 Paris, France',\n",
              "  'Rating': 4.7,\n",
              "  'Opening Hours': {'open_now': True},\n",
              "  'Location': {'lat': 48.8606111, 'lng': 2.337644},\n",
              "  'Phone': '+33 1 40 20 53 17',\n",
              "  'Photo': 'https://maps.googleapis.com/maps/api/place/photo?maxwidth=400&photoreference=AUjq9jkhturwQDRuo7k2Duuj51k3eDRswOKwKsSwsH-UVFoHG-qaMVKGvxouGWkVI6S7SFW8BFvNeKZJmkZLU7ZN1vOdXmanAi5w33nK2tR4ggpegOG-3Lq5p6B3V4ti2uS2nq9jj1ajU-mFH0MJusgUb7h9p_RX6o3T2gH9O147m8EBEHtG&key=AIzaSyCU7kaDfhZIM4bbJVujlGlhdXphUPke1yY'}]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(details)"
      ],
      "metadata": {
        "id": "qOIObiTZP39j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "places = df['Name'] + ', France'\n",
        "places"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ncMH-GvQPQ3",
        "outputId": "720756d9-b71f-433c-a424-e35b4a749696"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     Eiffel Tower, France\n",
              "1      Hoct & Loca, France\n",
              "2    Louvre Museum, France\n",
              "Name: Name, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ChatGPT Tagging"
      ],
      "metadata": {
        "id": "h_I19O2kzuh4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "import re"
      ],
      "metadata": {
        "id": "WBEIgfgaz2AN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "KEY = \"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\"\n",
        "openai.api_key = KEY\n",
        "engine = \"text-davinci-002\""
      ],
      "metadata": {
        "id": "PnxKe3yHPgbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PlaceDescriptionGenerator:\n",
        "    def __init__(self, openai_key):\n",
        "        self.openai_key = openai_key\n",
        "        self.engine = engine\n",
        "        openai.api_key = openai_key\n",
        "        \n",
        "        \n",
        "    def get_description(self,place_name):\n",
        "      # Set the prompt for the API\n",
        "      prompt = \"\"\"Get a 200 characters, accurate description about the \\n\\nRestaurant: \"\"\" + place_name+ \"\"\" from the internet,\n",
        "      you can use google description about the place or some other website to get description about this place. Description \n",
        "      should include place type, Ambience, what it provides, speciality, etc. Please generate accurate description.\n",
        "      \"\"\"\n",
        "      # Generate a response to the prompt\n",
        "      response = openai.Completion.create(\n",
        "          engine=self.engine,\n",
        "          prompt=prompt,\n",
        "          max_tokens=1024,\n",
        "          n=1,\n",
        "          stop=None,\n",
        "          temperature=0.7,\n",
        "      )\n",
        "\n",
        "      # Extract the generated text from the response\n",
        "      message = response.choices[0].text.strip()\n",
        "      \n",
        "      # Split the message into the description and tags\n",
        "      place_tokens = place_name.split(',')\n",
        "      for token in place_tokens:\n",
        "          message = message.replace(token, '')\n",
        "          message = message.replace(token, '')\n",
        "      return message\n",
        "    \n",
        "    def get_tags(self,description):\n",
        "      prompt = \"\"\"\n",
        "      Generate only three tags,each tag should not be more than 2 words long, from the \"\"\"+description+\"\"\", Note that out of three tags, one tag should be about place\n",
        "      type, for example is it cafe, restaurant, shopping place, spa, etc. second tag should be cuisine or another category \n",
        "      that describes the place, for example if it is Italian cafe, tag should be Italian, If it is museaum, the tag \n",
        "      should be art & History, etc. third tag should be something creative about the place, For example, if it is a roof-top \n",
        "      cafe third tag can be rooftop, If it is a shopping street famous for night-life, third tag should be night-life.\n",
        "      if it is site-seeing, third tag can be tourist attraction, etc. Note that each tag SHOULD NOT be more than 2\n",
        "      words long.\"\"\"\n",
        "      # Generate a response to the prompt\n",
        "      response = openai.Completion.create(\n",
        "          engine=engine,\n",
        "          prompt=prompt,\n",
        "          max_tokens=32,\n",
        "          n=1,\n",
        "          stop=None,\n",
        "          temperature=0.7,\n",
        "      )\n",
        "\n",
        "      # Extract the generated text from the response\n",
        "      message = response.choices[0].text.strip()\n",
        "      words_to_remove = ['Tag','Tags','input','tags','tag','Input','var','Place','place','type','Type','CODE','enter','YOUR  HERE','Output','here','list of','three','append']\n",
        "      message = message.replace('\\n',',')\n",
        "      clean_text = re.sub(\"[^A-Za-z,']+\", ' ', message)\n",
        "      for word in words_to_remove:\n",
        "          clean_text = clean_text.replace(word,'')\n",
        "      return clean_text\n",
        "      \n",
        "    def list_tag_data(self,data):\n",
        "      all_data = []\n",
        "      for place in data:\n",
        "        info = {}\n",
        "        des = self.get_description(place)\n",
        "        info['Tags'] = self.get_tags(des)\n",
        "        info['Description'] = des\n",
        "        all_data.append(info)\n",
        "      return all_data\n"
      ],
      "metadata": {
        "id": "E9Z0NZ4h-yIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tag_generator = PlaceDescriptionGenerator(openai_key = KEY)"
      ],
      "metadata": {
        "id": "cU7lST14CtjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tags = tag_generator.list_tag_data(places)"
      ],
      "metadata": {
        "id": "MuQYWSm7Ptlo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tags"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxczQcWQPrWZ",
        "outputId": "a9b504ae-c424-46ad-d4ea-e6b391dca7cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'Tags': 'Eiffel Tower, Tourist Attraction, Paris, Art History',\n",
              "  'Description': ' is a wrought iron lattice tower on the Champ de Mars in Paris,. It is named after the engineer Gustave Eiffel, whose company designed and built the tower.  is the most-visited paid monument in the world; 6.91 million people ascended it in 2015. The tower is 324 metres tall, about the same height as an 81-storey building, and the tallest structure in Paris. Its base is square, measuring 125 metres on each side. During its construction, the  surpassed the Washington Monument to become the tallest man-made structure in the world, a title it held for 41 years until the Chrysler Building in New York City was finished in 1930. Because of the addition of the aerial at the top of the tower in 1957, it is now taller than the Chrysler Building by 5.2 metres. Excluding transmitters, the  is the second-tallest structure in after the Millau Viaduct.'},\n",
              " {'Tags': ' French , Contemporary , Casual , ,, , name The National Gallery ,',\n",
              "  'Description': ' is a restaurant in that serves up traditional French cuisine with a modern twist. The restaurant has a casual yet chic vibe, and the menu features both classic and contemporary dishes.  is known for its fresh, seasonal ingredients and its inventive dishes. The restaurant also has an extensive wine list.'},\n",
              " {'Tags': \" , , if document getElementById museum checked true ,   ' museum\",\n",
              "  'Description': 'The  is one of the largest and most famous museums in the world. It is located in Paris,. The museum is home to many famous works of art, including the Mona Lisa. The Louvre is a must-see for anyone visiting Paris.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xvCNtXjXQ2cv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}